\section{Collective Communication Operations}

According to the MPI specification, collective communications can be expressed
using point-to-point operations and a reserved tag space. Most of the
derivations follow similar patterns, so we will present a few specific examples
rather than enumerating all of them.

\subsection{Example: broadcast}
The MPI broadcast operation is a one-to-many communication. It takes the message
and copies it into the receive buffer of each process in the group. This is
simply encoded by executing a send from the source to each process that is a
member of the group on the group's communicator. This is paired with a blocking
receive on each destination process in the group. We use non-blocking sends
grouped together with all of the witnessing waits following the sends. This is
necessary since the runtime can order the sends as it wishes in order to avoid
locking.

\subsection{Example: gather}
The gather operation is the complement of broadcast. The send buffer of each
process in the group is copied into the receive buffer of the destination
process. Each send is blocking, and the receives are non-blocking, with all of
the waits immediately following the last receive.

\subsection{Example: barrier}
A barrier guarantees that all processes in the group are synchronized at that
point in the schedule. In our encoding this is handled as a separate operation
as other derivations would require adding many more communication operations.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
